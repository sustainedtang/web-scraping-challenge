{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3610jvsc74a57bd0b432461d0a0115d0c9d901da8da6cafa7da0264c25770543bb182d5a47b20b85",
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "source": [
    "## Step 1 - Scraping\n",
    "### NASA Mars News\n",
    "Scrape the [Mars News Site](https://redplanetscience.com/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [C:\\Users\\Tang\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://redplanetscience.com\"\n",
    "browser.visit(url)\n",
    "time.sleep(1)\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NASA Establishes Board to Initially Review Mars Sample Return Plans\n----------------\nThe board will assist with analysis of current plans and goals for one of the most difficult missions humanity has ever undertaken.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the latest news title\n",
    "news_title=soup.find_all('div', class_='content_title')[0].text\n",
    "# Retrieve the latest news paragraph\n",
    "news_p=soup.find_all('div', class_='article_teaser_body')[0].text\n",
    "print(news_title)\n",
    "print(16*(\"-\"))\n",
    "print(news_p)"
   ]
  },
  {
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "* Visit the url for the Featured Space Image site [here](https://spaceimages-mars.com).\n",
    "\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "* Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "* Make sure to save a complete url string for this image."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://spaceimages-mars.com/image/featured/mars3.jpg\nDusty Space Cloud\n"
     ]
    }
   ],
   "source": [
    "jpl_url = \"https://spaceimages-mars.com/\"\n",
    "browser.visit(jpl_url)\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "#Find featured image\n",
    "featured_image_text = soup.find('h1', class_='media_feature_title').text.strip()\n",
    "featured_image_url = browser.find_by_tag('img[class=\"headerimage fade-in\"]')[0][\"src\"]\n",
    "print(featured_image_url)\n",
    "print(featured_image_text)\n"
   ]
  },
  {
   "source": [
    "## Mars Facts\n",
    "* Visit the Mars Facts webpage [here](https://galaxyfacts-mars.com) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "* Use Pandas to convert the data to a HTML table string."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>Mars</th>      <th>Earth</th>    </tr>    <tr>      <th>Mars - Earth Comparison</th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Diameter:</th>      <td>6,779 km</td>      <td>12,742 km</td>    </tr>    <tr>      <th>Mass:</th>      <td>6.39 × 10^23 kg</td>      <td>5.97 × 10^24 kg</td>    </tr>    <tr>      <th>Moons:</th>      <td>2</td>      <td>1</td>    </tr>    <tr>      <th>Distance from Sun:</th>      <td>227,943,824 km</td>      <td>149,598,262 km</td>    </tr>    <tr>      <th>Length of Year:</th>      <td>687 Earth days</td>      <td>365.24 days</td>    </tr>    <tr>      <th>Temperature:</th>      <td>-87 to -5 °C</td>      <td>-88 to 58°C</td>    </tr>  </tbody></table>'"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "facts_url = \"https://galaxyfacts-mars.com\"\n",
    "browser.visit(facts_url)\n",
    "facts_table = pd.read_html(facts_url, header=0, index_col=0)\n",
    "trimmed_table = facts_table[0]\n",
    "trimmed_table = trimmed_table.to_html()\n",
    "trimmed_table.replace('\\n','')"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "### Mars Hemispheres\n",
    "\n",
    "* Visit the astrogeology site [here](https://marshemispheres.com/) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/full.jpg'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/schiaparelli_enhanced-full.jpg'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/syrtis_major_enhanced-full.jpg'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/valles_marineris_enhanced-full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "hemi_url = \"https://marshemispheres.com/\"\n",
    "browser.visit(hemi_url)\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "mars_hems = soup.find('div',class_='collapsible results')\n",
    "mars_item = mars_hems.find_all('div',class_='item')\n",
    "hemisphere_image_urls=[]\n",
    "\n",
    "for i in mars_item:\n",
    "    #Description\n",
    "    hemisphere = i.find('div', class_=\"description\")\n",
    "    title = hemisphere.h3.text\n",
    "\n",
    "    #Image links\n",
    "    hemisphere_link = hemisphere.a[\"href\"]\n",
    "    browser.visit(hemi_url + hemisphere_link)\n",
    "    \n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "   \n",
    "\n",
    "    image_link = soup.find('div', class_='downloads')\n",
    "    image_url = image_link.find('li').a['href']\n",
    "   \n",
    "    #Dictionary\n",
    "    hemisphere_image_urls.append({\"title\": title, \"img_url\": (hemi_url + image_url)})\n",
    "    \n",
    "print(hemisphere_image_urls)\n",
    "browser.quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}